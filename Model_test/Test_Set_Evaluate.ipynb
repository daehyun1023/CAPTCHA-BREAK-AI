{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test_Set_Evaluate.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNCZRW/vka6/jucbEUl/XMo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yum-cloud-94/CAPTCHA-BREAK-AI/blob/CRNN_Modeling/Model_test/Test_Set_Evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCIiO6Y0Ly79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLfrjoG8L4ed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from time import time\n",
        "\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score,f1_score,precision_score,recall_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "print(\"Tensorflow version: \", tf.__version__)\n",
        "\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOg6CW9JL4gs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dir = \"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/testcaptcha/\"\n",
        "os.chdir(dir)\n",
        "# data_dir = Path(\"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/data/\")\n",
        "\n",
        "# Get list of all the images\n",
        "# images = list(data_dir.glob(\"*.png\"))\n",
        "images = os.listdir(dir)\n",
        "print(\"Number of images found: \", len(images))\n",
        "\n",
        "# Let's take a look at some samples first. \n",
        "# Always look at your data!\n",
        "\n",
        "_,ax = plt.subplots(2,2, figsize=(5,3))\n",
        "for i in range(4):\n",
        "    img = cv2.imread(images[i])\n",
        "    # img = cv2.imread(images[i])\n",
        "    # plt.imshow(img)\n",
        "    print(\"Shape of image: \", img.shape)\n",
        "    ax[i//2, i%2].imshow(img)\n",
        "    ax[i//2, i%2].axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7SFui78NL_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store all the characters in a set\n",
        "characters = set()\n",
        "\n",
        "# A list to store the length of each captcha\n",
        "captcha_length = []\n",
        "\n",
        "# Store image-label info\n",
        "dataset = []\n",
        "\n",
        "# Iterate over the dataset and store the\n",
        "# information needed\n",
        "for img_path in images:\n",
        "    # 1. Get the label associated with each image\n",
        "    label = img_path.split(\".\")[0]\n",
        "    if len(label)!=6:\n",
        "      continue\n",
        "\n",
        "    # 2. Store the length of this cpatcha\n",
        "    captcha_length.append(len(label))\n",
        "    # 3. Store the image-label pair info\n",
        "    dataset.append((str(img_path), label))\n",
        "    \n",
        "    # 4. Store the characters present\n",
        "    for ch in label:\n",
        "        characters.add(ch)\n",
        "\n",
        "# Sort the characters        \n",
        "characters = sorted(characters)\n",
        "\n",
        "# Convert the dataset info into a dataframe\n",
        "dataset = pd.DataFrame(dataset, columns=[\"img_path\", \"label\"], index=None)\n",
        "\n",
        "# Shuffle the dataset\n",
        "dataset = dataset.sample(frac=1.).reset_index(drop=True)\n",
        "test_data= dataset.copy()\n",
        "\n",
        "print(\"Number of unqiue charcaters in the whole dataset: \", len(characters))\n",
        "print(\"Maximum length of any captcha: \", max(Counter(captcha_length).keys()))\n",
        "print(\"Characters present: \", characters)\n",
        "print(\"Total number of samples in the dataset: \", len(dataset))\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpzcxucaL4m1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Map text to numeric labels \n",
        "char_to_labels = {char:idx for idx, char in enumerate(characters)}\n",
        "\n",
        "# Map numeric labels to text\n",
        "labels_to_char = {val:key for key, val in char_to_labels.items()}\n",
        "\n",
        "# Sanity check for corrupted images\n",
        "def is_valid_captcha(captcha):\n",
        "    for ch in captcha:\n",
        "        if not ch in characters:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "# Store arrays in memory as it's not a muvh big dataset\n",
        "def generate_arrays(df, resize=True, img_height=img.shape[0], img_width=img.shape[1]):\n",
        "    \"\"\"Generates image array and labels array from a dataframe.\n",
        "    \n",
        "    Args:\n",
        "        df: dataframe from which we want to read the data\n",
        "        resize (bool)    : whether to resize images or not\n",
        "        img_weidth (int): width of the resized images\n",
        "        img_height (int): height of the resized images\n",
        "        \n",
        "    Returns:\n",
        "        images (ndarray): grayscale images\n",
        "        labels (ndarray): corresponding encoded labels\n",
        "    \"\"\"\n",
        "    \n",
        "    num_items = len(df)\n",
        "    images = np.zeros((num_items, img_height, img_width), dtype=np.float32)\n",
        "    labels = [0]*num_items\n",
        "    \n",
        "    for i in range(num_items):\n",
        "        img = cv2.imread(df[\"img_path\"][i])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        if resize: \n",
        "            img = cv2.resize(img, (img_width, img_height))\n",
        "        \n",
        "        img = (img/255.).astype(np.float32)\n",
        "        label = df[\"label\"][i]\n",
        "        \n",
        "        # Add only if it is a valid captcha\n",
        "        if is_valid_captcha(label):\n",
        "            images[i, :, :] = img\n",
        "            labels[i] = label\n",
        "    \n",
        "    return images, np.array(labels)\n",
        "\n",
        "# Build training data\n",
        "test_data, test_labels = generate_arrays(df=test_data)\n",
        "print(\"Number of test images: \", test_data.shape)\n",
        "print(\"Number of test labels: \", test_labels.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z020YRbkL4rG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Generates batches from a given dataset.\n",
        "    \n",
        "    Args:\n",
        "        data: training or validation data\n",
        "        labels: corresponding labels\n",
        "        char_map: dictionary mapping char to labels\n",
        "        batch_size: size of a single batch\n",
        "        img_width: width of the resized\n",
        "        img_height: height of the resized\n",
        "        downsample_factor: by what factor did the CNN downsample the images\n",
        "        max_length: maximum length of any captcha\n",
        "        shuffle: whether to shuffle data or not after each epoch\n",
        "    Returns:\n",
        "        batch_inputs: a dictionary containing batch inputs \n",
        "        batch_labels: a batch of corresponding labels \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 data,\n",
        "                 labels,\n",
        "                 char_map,\n",
        "                 batch_size,\n",
        "                 img_width,\n",
        "                 img_height,\n",
        "                 downsample_factor,\n",
        "                 max_length,\n",
        "                 shuffle=True\n",
        "                ):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.char_map = char_map\n",
        "        self.batch_size = batch_size\n",
        "        self.img_width = img_width\n",
        "        self.img_height = img_height\n",
        "        self.downsample_factor = downsample_factor\n",
        "        self.max_length = max_length\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(data))    \n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.data) / self.batch_size))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # 1. Get the next batch indices\n",
        "        curr_batch_idx = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        \n",
        "        # 2. This isn't necessary but it can help us save some memory\n",
        "        # as not all batches the last batch may not have elements\n",
        "        # equal to the batch_size \n",
        "        batch_len = len(curr_batch_idx)\n",
        "        \n",
        "        # 3. Instantiate batch arrays\n",
        "        batch_images = np.ones((batch_len, self.img_width, self.img_height, 1),\n",
        "                               dtype=np.float32)\n",
        "        batch_labels = np.ones((batch_len, self.max_length), dtype=np.float32)\n",
        "        input_length = np.ones((batch_len, 1), dtype=np.int64) * \\\n",
        "                                (self.img_width // self.downsample_factor)\n",
        "        label_length = np.zeros((batch_len, 1), dtype=np.int64)\n",
        "        \n",
        "        \n",
        "        for j, idx in enumerate(curr_batch_idx):\n",
        "            # 1. Get the image and transpose it\n",
        "            img = self.data[idx].T\n",
        "            # 2. Add extra dimenison\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "            # 3. Get the correpsonding label\n",
        "            text = self.labels[idx]\n",
        "            # 4. Include the pair only if the captcha is valid\n",
        "            if is_valid_captcha(text):\n",
        "                label = [self.char_map[ch] for ch in text]\n",
        "                batch_images[j] = img\n",
        "                batch_labels[j] = label\n",
        "                label_length[j] = len(text)\n",
        "        \n",
        "        batch_inputs = {\n",
        "                'input_data': batch_images,\n",
        "                'input_label': batch_labels,\n",
        "                'input_length': input_length,\n",
        "                'label_length': label_length,\n",
        "                }\n",
        "        return batch_inputs, np.zeros(batch_len).astype(np.float32)\n",
        "        \n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZXTFcCmL4xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch size for training and validation\n",
        "batch_size = 16\n",
        "\n",
        "# Desired image dimensions\n",
        "img_width=img.shape[1]\n",
        "img_height=img.shape[0]\n",
        "\n",
        "# Factor  by which the image is going to be downsampled\n",
        "# by the convolutional blocks\n",
        "downsample_factor=8\n",
        "\n",
        "# Maximum length of any captcha in the data\n",
        "max_length=6\n",
        "\n",
        "# Get a generator object for the training data\n",
        "test_data_generator = DataGenerator(data=test_data,\n",
        "                                     labels=test_labels,\n",
        "                                     char_map=char_to_labels,\n",
        "                                     batch_size=batch_size,\n",
        "                                     img_width=img_width,\n",
        "                                     img_height=img_height,\n",
        "                                     downsample_factor=downsample_factor,\n",
        "                                     max_length=max_length,\n",
        "                                     shuffle=True\n",
        "                                    )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuVJQdMWdlp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CTCLayer(layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred, input_length, label_length):\n",
        "        # Compute the training-time loss value and add it\n",
        "        # to the layer using `self.add_loss()`.\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "        \n",
        "        # On test time, just return the computed loss\n",
        "        return loss\n",
        "\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    # Inputs to the model\n",
        "    input_img = layers.Input(shape=(img_width, img_height, 1),\n",
        "                            name='input_data',\n",
        "                            dtype='float32')\n",
        "    labels = layers.Input(name='input_label', shape=[max_length], dtype='float32')\n",
        "    input_length = layers.Input(name='input_length', shape=[1], dtype='int64')\n",
        "    label_length = layers.Input(name='label_length', shape=[1], dtype='int64')\n",
        "    \n",
        "    # First conv block\n",
        "    x = layers.Conv2D(64,\n",
        "               (3,3),\n",
        "               activation='relu',\n",
        "               kernel_initializer='he_normal',\n",
        "               padding='same',\n",
        "               name='Conv1')(input_img)\n",
        "    x = layers.MaxPooling2D((2,2), name='pool1')(x)\n",
        "    \n",
        "    x = layers.Conv2D(128,\n",
        "               (3,3),\n",
        "               activation='relu',\n",
        "               kernel_initializer='he_normal',\n",
        "               padding='same',\n",
        "               name='Conv2')(x)\n",
        "    x = layers.MaxPooling2D((2,2), name='pool2')(x)\n",
        "    \n",
        "    x = layers.Conv2D(256,\n",
        "               (3,3),\n",
        "               activation='relu',\n",
        "               kernel_initializer='he_normal',\n",
        "               padding='same',\n",
        "               name='Conv3')(x)\n",
        "    x = layers.MaxPooling2D((2,2), name='pool3')(x)\n",
        "    \n",
        "    # We have used two max pool with pool size and strides of 2.\n",
        "    # Hence, downsampled feature maps are 4x smaller. The number of\n",
        "    # filters in the last layer is 64. Reshape accordingly before\n",
        "    # passing it to RNNs\n",
        "    new_shape = ((img_width // 8), (img_height // 8)*256)\n",
        "    x = layers.Reshape(target_shape=new_shape, name='reshape')(x)\n",
        "    x = layers.Dense(256, activation='relu', name='dense1')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    \n",
        "    # RNNs\n",
        "    x = layers.Bidirectional(layers.LSTM(512,\n",
        "                                         return_sequences=True,\n",
        "                                         dropout=0.2))(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(256,\n",
        "                                         return_sequences=True,\n",
        "                                         dropout=0.25))(x)\n",
        "\n",
        "    # x = layers.Bidirectional(layers.LSTM(128,\n",
        "    #                                      return_sequences=True,\n",
        "    #                                      dropout=0.25))(x)\n",
        "\n",
        "    # Predictions\n",
        "    x = layers.Dense(len(characters)+1,\n",
        "              activation='softmax', \n",
        "              name='dense2',\n",
        "              kernel_initializer='he_normal')(x)\n",
        "    \n",
        "    # Calculate CTC\n",
        "    output = CTCLayer(name='ctc_loss')(labels, x, input_length, label_length)\n",
        "    \n",
        "    # Define the model\n",
        "    model = keras.models.Model(inputs=[input_img,\n",
        "                                       labels,\n",
        "                                       input_length,\n",
        "                                       label_length],\n",
        "                                outputs=output,\n",
        "                                name='ocr_model_v1')\n",
        "    \n",
        "    # Optimizer\n",
        "    sgd = keras.optimizers.SGD(learning_rate=0.005,\n",
        "                               decay=1e-6,\n",
        "                               momentum=0.9,\n",
        "                               nesterov=True,\n",
        "                               clipnorm=5)\n",
        "    \n",
        "    # Compile the model and return \n",
        "    model.compile(optimizer=sgd, metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1eWd2HZL41p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.compat.v2.keras.models import model_from_json\n",
        "\n",
        "# json file 열기\n",
        "json_file = open(\"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/model/captcha_prediction_model.json\", \"r\")\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "# json파일로부터 model load\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# model에 weight 로드하기\n",
        "weight = '/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/model/captcha_prediction_weight.h5'\n",
        "loaded_model.load_weights(weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaFxLoVtdJsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model = model_from_json(loaded_model_json,custom_objects={'CTCLayer': CTCLayer})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We9WPD83L48Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A utility to decode the output of the network\n",
        "def decode_batch_predictions(pred):\n",
        "    pred = pred[:, :-2]\n",
        "    input_len = np.ones(pred.shape[0])*pred.shape[1]\n",
        "    \n",
        "    # Use greedy search. For complex tasks, you can use beam search\n",
        "    results = keras.backend.ctc_decode(pred, \n",
        "                                        input_length=input_len,\n",
        "                                        greedy=True)[0][0]\n",
        "    \n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for res in results.numpy():\n",
        "        outstr = ''\n",
        "        for c in res:\n",
        "            if c < len(characters) and c >=0:\n",
        "                outstr += labels_to_char[c]\n",
        "        output_text.append(outstr)\n",
        "    \n",
        "    # return final text results\n",
        "    return output_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCLiHLN-L5Av",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g0ZxUHeL5Gz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size=len(validation_labels)\n",
        "curr_idx=np.arange(size)\n",
        "\n",
        "def make_xy(x,y):\n",
        "  global image_width\n",
        "  global image_heigh\n",
        "  global max_length\n",
        "\n",
        "  size=len(y)\n",
        "  curr_idx=np.arange(size)\n",
        "\n",
        "  X = np.ones((size, 150, 50, 1),dtype=np.float32)\n",
        "  Y = np.ones((size, 6), dtype=np.float32)\n",
        "  for j,idx in enumerate(curr_idx):\n",
        "    img=x[idx].T\n",
        "    img=np.expand_dims(img,axis=-1)\n",
        "    text=y[idx]\n",
        "  if is_valid_captcha(text):\n",
        "    label=[char to labels[ch] for ch in text]\n",
        "    X[j]=img\n",
        "    Y[j]=label\n",
        "  return X,Y\n",
        "\n",
        "# input_length = np.ones((batch_len, 1), dtype=np.int64) * \\\n",
        "#                         (self.img_width // self.downsample_factor - 2)\n",
        "# label_length = np.zeros((batch_len, 1), dtype=np.int64)\n",
        "\n",
        "# for j, idx in enumerate(curr_idx):\n",
        "#   # 1. Get the image and transpose it\n",
        "#   img = validation_data[idx].T\n",
        "#   # 2. Add extra dimenison\n",
        "#   img = np.expand_dims(img, axis=-1)\n",
        "#   # 3. Get the correpsonding label\n",
        "#   text = validation_labels[idx]\n",
        "#   # 4. Include the pair only if the captcha is valid\n",
        "#   if is_valid_captcha(text):\n",
        "#     label = [char_to_labels[ch] for ch in text]\n",
        "#     X[j] = img\n",
        "#     Y[j] = label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT5HWTeqKkho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X,Y=make_xy(test_data,test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM9GL_C2L5LQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_eval(x,y,model):\n",
        "\n",
        "  preds=model.predict(x)\n",
        "  pred_texts=decode_batch_predictions(preds)\n",
        "  cnt=0\n",
        "  orig_texts = []\n",
        "  for label in y:\n",
        "      text = ''.join([labels_to_char[int(x)] for x in label])\n",
        "      orig_texts.append(text)\n",
        "  \n",
        "  for i in range(len(y)):\n",
        "    if pred_texts[i]==orig_texts[i]:\n",
        "      cnt=cnt+1\n",
        "  print(cnt)\n",
        "  return cnt/len(pred_texts)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNXIc_wiL5PX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc=my_eval(X,Y,prediction_model)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-e2nqg3L5T0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}