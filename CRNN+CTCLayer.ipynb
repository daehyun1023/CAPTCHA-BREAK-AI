{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CRNN+CTCLayer.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNfgVE8I40X752+0FfG4GNB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yum-cloud-94/CAPTCHA-BREAK-AI/blob/CRNN_Modeling/CRNN%2BCTCLayer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tel60fyIQprJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RZQJWY6Qmro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import errno\n",
        "from time import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tempfile\n",
        "from PIL import Image\n",
        "import PIL\n",
        "\n",
        "from pathlib import Path \n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# directory remove\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs1PUJxYREE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dh_dir = 'C:/Users/admin/Desktop/captcha/'\n",
        "# image_dir='C:/Users/admin/Desktop/captcha/data'\n",
        "# captcha_dir='C:/Users/admin/Desktop/captcha/'\n",
        "\n",
        "captcha_dir=\"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/\"\n",
        "image_dir=\"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/data/\"\n",
        "new_dir=\"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/newdata/\"\n",
        "claptcha_dir=\"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/claptcha/\"\n",
        "six_dir=\"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/six_data_font/\"\n",
        "\n",
        "dir={'captcha':captcha_dir,'kaggle':image_dir,'new_kaggle':new_dir,\n",
        "     'claptcha':claptcha_dir,'six':six_dir}\n",
        "\n",
        "data_dir=Path(dir['claptcha'])\n",
        "os.chdir(dir['claptcha'])\n",
        "\n",
        "image_list=os.listdir(dir['claptcha'])\n",
        "\n",
        "seed=1234\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCgTE0tNaL2x",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBG5uWKrREHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = list(data_dir.glob(\"*.png\"))\n",
        "print(\"Number of images found: \", len(images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goQEodLbREI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_images = images[:4]\n",
        "_,ax = plt.subplots(2,2, figsize=(5,3))\n",
        "for i in range(4):\n",
        "    img = cv2.imread(str(sample_images[i]))\n",
        "    print(\"Shape of image: \", img.shape)\n",
        "    ax[i//2, i%2].imshow(img)\n",
        "    ax[i//2, i%2].axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrt137n26O8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hegiht, width of image\n",
        "img_height=80\n",
        "img_width=200\n",
        "\n",
        "# Store all the characters in a set\n",
        "characters = set()\n",
        "\n",
        "# A list to store the length of each captcha\n",
        "captcha_length = []\n",
        "\n",
        "# Store image-label info\n",
        "dataset = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSIAq-mo6O52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Iterate over the dataset and store the\n",
        "# information needed\n",
        "for img_path in images:\n",
        "    # 1. Get the label associated with each image\n",
        "    label = img_path.name.split(\".png\")[0]\n",
        "    # 2. Store the length of this cpatcha\n",
        "    captcha_length.append(len(label))\n",
        "    # 3. Store the image-label pair info\n",
        "    dataset.append((str(img_path), label))\n",
        "    \n",
        "    # 4. Store the characters present\n",
        "    for ch in label:\n",
        "        characters.add(ch)\n",
        "\n",
        "print('dataset[0]: ',dataset[0])\n",
        "print('captcha_length[0]',captcha_length[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8vvmvqjoVXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sort the characters        \n",
        "characters = sorted(characters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlSzM-Z9oVIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the dataset info into a dataframe\n",
        "dataset = pd.DataFrame(dataset, columns=[\"img_path\", \"label\"], index=None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ_g065dC-_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffle the dataset\n",
        "dataset = dataset.sample(frac=1.).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVLh60G6C_Co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Number of unqiue charcaters in the whole dataset: \", len(characters))\n",
        "print(\"Maximum length of any captcha: \", max(Counter(captcha_length).keys()))\n",
        "print(\"Characters present: \", characters)\n",
        "print(\"Total number of samples in the dataset: \", len(dataset))\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK4VJ9x2C_FS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data, validation_data = train_test_split(dataset, test_size=0.2, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zbRQF8KC_II",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = training_data.reset_index(drop=True)\n",
        "validation_data = validation_data.reset_index(drop=True)\n",
        "\n",
        "print(\"Number of training samples: \", len(training_data))\n",
        "print(\"Number of validation samples: \", len(validation_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZyS96X0C_Kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Map text to numeric labels \n",
        "char_to_labels = {char:idx for idx, char in enumerate(characters)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYJvk9ZpC_PU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Map numeric labels to text\n",
        "labels_to_char = {val:key for key, val in char_to_labels.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gmk33WkC_SD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sanity check for corrupted images\n",
        "# label이 characters안에 있는지 확인\n",
        "def is_valid_captcha(captcha):\n",
        "    for ch in captcha:\n",
        "        if not ch in characters:\n",
        "            return False\n",
        "    return True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qPAfC4KC_WV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store arrays in memory as it's not a much big dataset\n",
        "# 데이터셋이 너무 크지는 않기 때문에 메모리에 배열 저장\n",
        "\n",
        "def generate_arrays(df, resize=True, img_height=img_height, img_width=img_width):\n",
        "    \"\"\"Generates image array and labels array from a dataframe.\n",
        "    \n",
        "    Args:\n",
        "        df: dataframe from which we want to read the data\n",
        "        resize (bool)    : whether to resize images or not\n",
        "        img_weidth (int): width of the resized images\n",
        "        img_height (int): height of the resized images\n",
        "        \n",
        "    Returns:\n",
        "        images (ndarray): grayscale images\n",
        "        labels (ndarray): corresponding encoded labels\n",
        "    \"\"\"\n",
        "    \n",
        "    num_items = len(df)\n",
        "    images = np.zeros((num_items, img_height, img_width), dtype=np.float32)\n",
        "    labels = [0]*num_items\n",
        "    \n",
        "    for i in range(num_items):\n",
        "        img = cv2.imread(df[\"img_path\"][i])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        if resize: \n",
        "            img = cv2.resize(img, (img_width, img_height))\n",
        "        \n",
        "        img = (img/255.).astype(np.float32)\n",
        "        label = df[\"label\"][i]\n",
        "        \n",
        "        # Add only if it is a valid captcha\n",
        "        if is_valid_captcha(label):\n",
        "            images[i, :, :] = img\n",
        "            labels[i] = label\n",
        "    \n",
        "    return images, np.array(labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlLQ_RgHC_Yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build training data\n",
        "training_data, training_labels = generate_arrays(df=training_data)\n",
        "print(\"Number of training images: \", training_data.shape)\n",
        "print(\"Number of training labels: \", training_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtHT-dd5C_bg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_data, validation_labels = generate_arrays(df=validation_data)\n",
        "print(\"Number of validation images: \", validation_data.shape)\n",
        "print(\"Number of validation labels: \", validation_labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQvryJ4RC_ds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Generates batches from a given dataset.\n",
        "    \n",
        "    Args:\n",
        "        data: training or validation data\n",
        "        labels: corresponding labels\n",
        "        char_map: dictionary mapping char to labels\n",
        "        batch_size: size of a single batch\n",
        "        img_width: width of the resized\n",
        "        img_height: height of the resized\n",
        "        downsample_factor: by what factor did the CNN downsample the images\n",
        "        max_length: maximum length of any captcha\n",
        "        shuffle: whether to shuffle data or not after each epoch\n",
        "    Returns:\n",
        "        batch_inputs: a dictionary containing batch inputs \n",
        "        batch_labels: a batch of corresponding labels \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 data,\n",
        "                 labels,\n",
        "                 char_map,\n",
        "                 batch_size=16,\n",
        "                 img_width=200,\n",
        "                 img_height=50,\n",
        "                 downsample_factor=4,\n",
        "                 max_length=5,\n",
        "                 shuffle=True\n",
        "                ):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.char_map = char_map\n",
        "        self.batch_size = batch_size\n",
        "        self.img_width = img_width\n",
        "        self.img_height = img_height\n",
        "        self.downsample_factor = downsample_factor\n",
        "        self.max_length = max_length\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(data))    \n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.data) / self.batch_size))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # 1. Get the next batch indices\n",
        "        curr_batch_idx = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        \n",
        "        # 2. This isn't necessary but it can help us save some memory\n",
        "        # as not all batches the last batch may not have elements\n",
        "        # equal to the batch_size \n",
        "        batch_len = len(curr_batch_idx)\n",
        "        \n",
        "        # 3. Instantiate batch arrays\n",
        "        batch_images = np.ones((batch_len, self.img_width, self.img_height, 1),\n",
        "                               dtype=np.float32)\n",
        "        batch_labels = np.ones((batch_len, self.max_length), dtype=np.float32)\n",
        "        input_length = np.ones((batch_len, 1), dtype=np.int64) * \\\n",
        "                                (self.img_width // self.downsample_factor - 2)\n",
        "        label_length = np.zeros((batch_len, 1), dtype=np.int64)\n",
        "        \n",
        "        \n",
        "        for j, idx in enumerate(curr_batch_idx):\n",
        "            # 1. Get the image and transpose it\n",
        "            img = self.data[idx].T\n",
        "            # 2. Add extra dimenison\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "            # 3. Get the correpsonding label\n",
        "            text = self.labels[idx]\n",
        "            # 4. Include the pair only if the captcha is valid\n",
        "            if is_valid_captcha(text):\n",
        "                label = [self.char_map[ch] for ch in text]\n",
        "                batch_images[j] = img\n",
        "                batch_labels[j] = label\n",
        "                label_length[j] = len(text)\n",
        "        \n",
        "        batch_inputs = {\n",
        "                'input_data': batch_images,\n",
        "                'input_label': batch_labels,\n",
        "                'input_length': input_length,\n",
        "                'label_length': label_length,\n",
        "                }\n",
        "        return batch_inputs, np.zeros(batch_len).astype(np.float32)\n",
        "        \n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72dmrZ9tC_hj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch size for training and validation\n",
        "batch_size = 100\n",
        "\n",
        "# Desired image dimensions\n",
        "img_width=200\n",
        "img_height=80 \n",
        "\n",
        "# Factor  by which the image is going to be downsampled\n",
        "# by the convolutional blocks\n",
        "downsample_factor=4\n",
        "\n",
        "# Maximum length of any captcha in the data\n",
        "max_length=6\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idQo_d56C_j2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get a generator object for the training data\n",
        "train_data_generator = DataGenerator(data=training_data,\n",
        "                                     labels=training_labels,\n",
        "                                     char_map=char_to_labels,\n",
        "                                     batch_size=batch_size,\n",
        "                                     img_width=img_width,\n",
        "                                     img_height=img_height,\n",
        "                                     downsample_factor=downsample_factor,\n",
        "                                     max_length=max_length,\n",
        "                                     shuffle=True\n",
        "                                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31xXsvnGC_Ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get a generator object for the validation data \n",
        "valid_data_generator = DataGenerator(data=validation_data,\n",
        "                                     labels=validation_labels,\n",
        "                                     char_map=char_to_labels,\n",
        "                                     batch_size=batch_size,\n",
        "                                     img_width=img_width,\n",
        "                                     img_height=img_height,\n",
        "                                     downsample_factor=downsample_factor,\n",
        "                                     max_length=max_length,\n",
        "                                     shuffle=False\n",
        "                                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1MoXTLTH5uP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CTCLayer(layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred, input_length, label_length):\n",
        "        # Compute the training-time loss value and add it\n",
        "        # to the layer using `self.add_loss()`.\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "        \n",
        "        # On test time, just return the computed loss\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiN1U-SfH5wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    # Inputs to the model\n",
        "    input_img = layers.Input(shape=(img_width, img_height, 1),\n",
        "                            name='input_data',\n",
        "                            dtype='float32')\n",
        "    labels = layers.Input(name='input_label', shape=[max_length], dtype='float32')\n",
        "    input_length = layers.Input(name='input_length', shape=[1], dtype='int64')\n",
        "    label_length = layers.Input(name='label_length', shape=[1], dtype='int64')\n",
        "    \n",
        "    # First conv block\n",
        "    x = layers.Conv2D(32,\n",
        "               (3,3),\n",
        "               activation='relu',\n",
        "               kernel_initializer='he_normal',\n",
        "               padding='same',\n",
        "               name='Conv1')(input_img)\n",
        "    x = layers.MaxPooling2D((2,2), name='pool1')(x)\n",
        "    \n",
        "    # Second conv block\n",
        "    x = layers.Conv2D(64,\n",
        "               (3,3),\n",
        "               activation='relu',\n",
        "               kernel_initializer='he_normal',\n",
        "               padding='same',\n",
        "               name='Conv2')(x)\n",
        "    x = layers.MaxPooling2D((2,2), name='pool2')(x)\n",
        "    \n",
        "    # We have used two max pool with pool size and strides of 2.\n",
        "    # Hence, downsampled feature maps are 4x smaller. The number of\n",
        "    # filters in the last layer is 64. Reshape accordingly before\n",
        "    # passing it to RNNs\n",
        "    new_shape = ((img_width // 4), (img_height // 4)*64)\n",
        "    x = layers.Reshape(target_shape=new_shape, name='reshape')(x)\n",
        "    x = layers.Dense(64, activation='relu', name='dense1')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    \n",
        "    # RNNs\n",
        "    x = layers.Bidirectional(layers.LSTM(128,\n",
        "                                         return_sequences=True,\n",
        "                                         dropout=0.2))(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(64,\n",
        "                                         return_sequences=True,\n",
        "                                         dropout=0.25))(x)\n",
        "    \n",
        "    # Predictions\n",
        "    x = layers.Dense(len(characters)+1,\n",
        "              activation='softmax', \n",
        "              name='dense2',\n",
        "              kernel_initializer='he_normal')(x)\n",
        "    \n",
        "    # Calculate CTC\n",
        "    output = CTCLayer(name='ctc_loss')(labels, x, input_length, label_length)\n",
        "    \n",
        "    # Define the model\n",
        "    model = keras.models.Model(inputs=[input_img,\n",
        "                                       labels,\n",
        "                                       input_length,\n",
        "                                       label_length],\n",
        "                                outputs=output,\n",
        "                                name='ocr_model_v1')\n",
        "    \n",
        "    # Optimizer\n",
        "    # sgd = keras.optimizers.SGD(learning_rate=0.002,\n",
        "    #                            decay=1e-6,\n",
        "    #                            momentum=0.9,\n",
        "    #                            nesterov=True,\n",
        "    #                            clipnorm=5)\n",
        "    \n",
        "    adadelta=keras.optimizers.Adadelta(lr=0.005)\n",
        "\n",
        "\n",
        "    # Compile the model and return \n",
        "    model.compile(optimizer=adadelta,metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWbYof2pH5zH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2ifRNHjH53N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add early stopping\n",
        "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                   patience=5,\n",
        "                                   restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_data_generator,\n",
        "                    validation_data=valid_data_generator,\n",
        "                    epochs=50,\n",
        "                    callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tr38C_bH56F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_model = keras.models.Model(model.get_layer(name='input_data').input,\n",
        "                                        model.get_layer(name='dense2').output)\n",
        "# prediction_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUdlEs2QH59T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_batch_predictions(pred):\n",
        "    print()\n",
        "    pred = pred[:, :-2]\n",
        "    input_len = np.ones(pred.shape[0])*pred.shape[1]\n",
        "    \n",
        "    # Use greedy search. For complex tasks, you can use beam search\n",
        "    results = keras.backend.ctc_decode(pred, \n",
        "                                        input_length=input_len,\n",
        "                                        greedy=True)[0][0]\n",
        "    \n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for res in results.numpy():\n",
        "        outstr = ''\n",
        "        for c in res:\n",
        "            if c < len(characters) and c >=0:\n",
        "                outstr += labels_to_char[c]\n",
        "        output_text.append(outstr)\n",
        "    \n",
        "    # return final text results\n",
        "    return output_text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQTKyphoH6AJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  Let's check results on some validation samples\n",
        "for p, (inp_value, _) in enumerate(valid_data_generator):\n",
        "    bs = inp_value['input_data'].shape[0]\n",
        "    X_data = inp_value['input_data']\n",
        "    labels = inp_value['input_label']\n",
        "    \n",
        "    preds = prediction_model.predict(X_data)\n",
        "    pred_texts = decode_batch_predictions(preds)\n",
        "    \n",
        "    \n",
        "    orig_texts = []\n",
        "    for label in labels:\n",
        "        text = ''.join([labels_to_char[int(x)] for x in label])\n",
        "        orig_texts.append(text)\n",
        "        \n",
        "    for i in range(bs):\n",
        "        print(f'Ground truth: {orig_texts[i]} \\t Predicted: {pred_texts[i]}')\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5WK9fVlH58R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_Bdua7PH51V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NT-M8w5C_Nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSi90qXXoVCP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}