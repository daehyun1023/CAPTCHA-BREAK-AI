{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessed_CAPTCHA_Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yum-cloud-94/CAPTCHA-BREAK-AI/blob/CRNN_Modeling/modeling/preprocessed_CAPTCHA_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxxdRZZdUX2j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "cab1b476-05d9-400d-96df-4ffb29c712ce"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x4vCHO7UKVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "767e061f-2a68-447a-e5b3-206dc8ae3a90"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "print(\"Tensorflow version: \", tf.__version__)\n",
        "\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version:  2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHK5HsddWaQk",
        "colab_type": "text"
      },
      "source": [
        "# Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94foPai3UWSt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "201dfc2b-f7c2-47b8-9eb4-d9668ceabb15"
      },
      "source": [
        "dir = \"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/newcaptcha/\"\n",
        "os.chdir(dir)\n",
        "# data_dir = Path(\"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/data/\")\n",
        "\n",
        "# Get list of all the images\n",
        "# images = list(data_dir.glob(\"*.png\"))\n",
        "images = os.listdir(dir)\n",
        "# images = images[:2000]\n",
        "print(\"Number of images found: \", len(images))\n",
        "\n",
        "\n",
        "# Let's take a look at some samples first. \n",
        "# Always look at your data!\n",
        "\n",
        "_,ax = plt.subplots(2,2, figsize=(5,3))\n",
        "for i in range(4):\n",
        "    img = cv2.imread(images[i])\n",
        "    # img = cv2.imread(images[i])\n",
        "    # plt.imshow(img)\n",
        "    print(\"Shape of image: \", img.shape)\n",
        "    ax[i//2, i%2].imshow(img)\n",
        "    ax[i//2, i%2].axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images found:  10000\n",
            "Shape of image:  (50, 150, 3)\n",
            "Shape of image:  (50, 150, 3)\n",
            "Shape of image:  (50, 150, 3)\n",
            "Shape of image:  (50, 150, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x216 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C71chhsJYKyx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "c3749b74-4c3f-4527-de08-48b38539648b"
      },
      "source": [
        "# Store all the characters in a set\n",
        "characters = set()\n",
        "\n",
        "# A list to store the length of each captcha\n",
        "captcha_length = []\n",
        "\n",
        "# Store image-label info\n",
        "dataset = []\n",
        "\n",
        "# Iterate over the dataset and store the\n",
        "# information needed\n",
        "for img_path in images:\n",
        "    # 1. Get the label associated with each image\n",
        "    label = img_path.split(\".\")[0]\n",
        "    if len(label)!=6:\n",
        "      continue\n",
        "    # 2. Store the length of this cpatcha\n",
        "    captcha_length.append(len(label))\n",
        "    # 3. Store the image-label pair info\n",
        "    dataset.append((str(img_path), label))\n",
        "    \n",
        "    # 4. Store the characters present\n",
        "    for ch in label:\n",
        "        characters.add(ch)\n",
        "\n",
        "# Sort the characters        \n",
        "characters = sorted(characters)\n",
        "\n",
        "# Convert the dataset info into a dataframe\n",
        "dataset = pd.DataFrame(dataset, columns=[\"img_path\", \"label\"], index=None)\n",
        "\n",
        "# Shuffle the dataset\n",
        "dataset = dataset.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"Number of unqiue charcaters in the whole dataset: \", len(characters))\n",
        "print(\"Maximum length of any captcha: \", max(Counter(captcha_length).keys()))\n",
        "print(\"Characters present: \", characters)\n",
        "print(\"Total number of samples in the dataset: \", len(dataset))\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unqiue charcaters in the whole dataset:  36\n",
            "Maximum length of any captcha:  6\n",
            "Characters present:  ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "Total number of samples in the dataset:  9992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4x81zy.png</td>\n",
              "      <td>4x81zy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a7uepk.png</td>\n",
              "      <td>a7uepk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9y07z7.png</td>\n",
              "      <td>9y07z7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wc2l86.png</td>\n",
              "      <td>wc2l86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9sife4.png</td>\n",
              "      <td>9sife4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     img_path   label\n",
              "0  4x81zy.png  4x81zy\n",
              "1  a7uepk.png  a7uepk\n",
              "2  9y07z7.png  9y07z7\n",
              "3  wc2l86.png  wc2l86\n",
              "4  9sife4.png  9sife4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su7oiFHfWgHu",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCRY2NsRYls0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c034d007-8c04-445f-9d25-4e2890f581b0"
      },
      "source": [
        "# Split the dataset into training and validation sets\n",
        "training_data, validation_data = train_test_split(dataset, test_size=0.2, random_state=seed)\n",
        "\n",
        "training_data = training_data.reset_index(drop=True)\n",
        "validation_data = validation_data.reset_index(drop=True)\n",
        "\n",
        "print(\"Number of training samples: \", len(training_data))\n",
        "print(\"Number of validation samples: \", len(validation_data))\n",
        "\n",
        "\n",
        "# Map text to numeric labels \n",
        "char_to_labels = {char:idx for idx, char in enumerate(characters)}\n",
        "\n",
        "# Map numeric labels to text\n",
        "labels_to_char = {val:key for key, val in char_to_labels.items()}\n",
        "\n",
        "\n",
        "# Sanity check for corrupted images\n",
        "def is_valid_captcha(captcha):\n",
        "    for ch in captcha:\n",
        "        if not ch in characters:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "# Store arrays in memory as it's not a muvh big dataset\n",
        "def generate_arrays(df, resize=True, img_height=50, img_width=150):\n",
        "    \"\"\"Generates image array and labels array from a dataframe.\n",
        "    \n",
        "    Args:\n",
        "        df: dataframe from which we want to read the data\n",
        "        resize (bool)    : whether to resize images or not\n",
        "        img_weidth (int): width of the resized images\n",
        "        img_height (int): height of the resized images\n",
        "        \n",
        "    Returns:\n",
        "        images (ndarray): grayscale images\n",
        "        labels (ndarray): corresponding encoded labels\n",
        "    \"\"\"\n",
        "    \n",
        "    num_items = len(df)\n",
        "    images = np.zeros((num_items, img_height, img_width), dtype=np.float32)\n",
        "    labels = [0]*num_items\n",
        "    \n",
        "    for i in range(num_items):\n",
        "        img = cv2.imread(df[\"img_path\"][i])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        if resize: \n",
        "            img = cv2.resize(img, (img_width, img_height))\n",
        "        \n",
        "        img = (img/255.).astype(np.float32)\n",
        "        label = df[\"label\"][i]\n",
        "        \n",
        "        # Add only if it is a valid captcha\n",
        "        if is_valid_captcha(label):\n",
        "            images[i, :, :] = img\n",
        "            labels[i] = label\n",
        "    \n",
        "    return images, np.array(labels)\n",
        "\n",
        "# Build training data\n",
        "training_data, training_labels = generate_arrays(df=training_data)\n",
        "print(\"Number of training images: \", training_data.shape)\n",
        "print(\"Number of training labels: \", training_labels.shape)\n",
        "\n",
        "\n",
        "# Build validation data\n",
        "validation_data, validation_labels = generate_arrays(df=validation_data)\n",
        "print(\"Number of validation images: \", validation_data.shape)\n",
        "print(\"Number of validation labels: \", validation_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples:  7993\n",
            "Number of validation samples:  1999\n",
            "Number of training images:  (7993, 50, 150)\n",
            "Number of training labels:  (7993,)\n",
            "Number of validation images:  (1999, 50, 150)\n",
            "Number of validation labels:  (1999,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlZtaB8Wdh83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Generates batches from a given dataset.\n",
        "    \n",
        "    Args:\n",
        "        data: training or validation data\n",
        "        labels: corresponding labels\n",
        "        char_map: dictionary mapping char to labels\n",
        "        batch_size: size of a single batch\n",
        "        img_width: width of the resized\n",
        "        img_height: height of the resized\n",
        "        downsample_factor: by what factor did the CNN downsample the images\n",
        "        max_length: maximum length of any captcha\n",
        "        shuffle: whether to shuffle data or not after each epoch\n",
        "    Returns:\n",
        "        batch_inputs: a dictionary containing batch inputs \n",
        "        batch_labels: a batch of corresponding labels \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 data,\n",
        "                 labels,\n",
        "                 char_map,\n",
        "                 batch_size=16,\n",
        "                 img_width=150,\n",
        "                 img_height=50,\n",
        "                 downsample_factor=8,\n",
        "                 max_length=6,\n",
        "                 shuffle=True\n",
        "                ):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.char_map = char_map\n",
        "        self.batch_size = batch_size\n",
        "        self.img_width = img_width\n",
        "        self.img_height = img_height\n",
        "        self.downsample_factor = downsample_factor\n",
        "        self.max_length = max_length\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(data))    \n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.data) / self.batch_size))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # 1. Get the next batch indices\n",
        "        curr_batch_idx = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        \n",
        "        # 2. This isn't necessary but it can help us save some memory\n",
        "        # as not all batches the last batch may not have elements\n",
        "        # equal to the batch_size \n",
        "        batch_len = len(curr_batch_idx)\n",
        "        \n",
        "        # 3. Instantiate batch arrays\n",
        "        batch_images = np.ones((batch_len, self.img_width, self.img_height, 1),\n",
        "                               dtype=np.float32)\n",
        "        batch_labels = np.ones((batch_len, self.max_length), dtype=np.float32)\n",
        "        input_length = np.ones((batch_len, 1), dtype=np.int64) * \\\n",
        "                                (self.img_width // self.downsample_factor - 2)\n",
        "        label_length = np.zeros((batch_len, 1), dtype=np.int64)\n",
        "        \n",
        "        \n",
        "        for j, idx in enumerate(curr_batch_idx):\n",
        "            # 1. Get the image and transpose it\n",
        "            img = self.data[idx].T\n",
        "            # 2. Add extra dimenison\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "            # 3. Get the correpsonding label\n",
        "            text = self.labels[idx]\n",
        "            # 4. Include the pair only if the captcha is valid\n",
        "            if is_valid_captcha(text):\n",
        "                label = [self.char_map[ch] for ch in text]\n",
        "                batch_images[j] = img\n",
        "                batch_labels[j] = label\n",
        "                label_length[j] = len(text)\n",
        "        \n",
        "        batch_inputs = {\n",
        "                'input_data': batch_images,\n",
        "                'input_label': batch_labels,\n",
        "                'input_length': input_length,\n",
        "                'label_length': label_length,\n",
        "                }\n",
        "        return batch_inputs, np.zeros(batch_len).astype(np.float32)\n",
        "        \n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdJzqNUUdhyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch size for training and validation\n",
        "batch_size = 16\n",
        "\n",
        "# Desired image dimensions\n",
        "img_width=150\n",
        "img_height=50 \n",
        "\n",
        "# Factor  by which the image is going to be downsampled\n",
        "# by the convolutional blocks\n",
        "downsample_factor=8\n",
        "\n",
        "# Maximum length of any captcha in the data\n",
        "max_length=6\n",
        "\n",
        "# Get a generator object for the training data\n",
        "train_data_generator = DataGenerator(data=training_data,\n",
        "                                     labels=training_labels,\n",
        "                                     char_map=char_to_labels,\n",
        "                                     batch_size=batch_size,\n",
        "                                     img_width=img_width,\n",
        "                                     img_height=img_height,\n",
        "                                     downsample_factor=downsample_factor,\n",
        "                                     max_length=max_length,\n",
        "                                     shuffle=True\n",
        "                                    )\n",
        "\n",
        "# Get a generator object for the validation data \n",
        "valid_data_generator = DataGenerator(data=validation_data,\n",
        "                                     labels=validation_labels,\n",
        "                                     char_map=char_to_labels,\n",
        "                                     batch_size=batch_size,\n",
        "                                     img_width=img_width,\n",
        "                                     img_height=img_height,\n",
        "                                     downsample_factor=downsample_factor,\n",
        "                                     max_length=max_length,\n",
        "                                     shuffle=False\n",
        "                                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjJT2UQBWmZP",
        "colab_type": "text"
      },
      "source": [
        "# Make model and fitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORU_YbwLdhqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CTCLayer(layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred, input_length, label_length):\n",
        "        # Compute the training-time loss value and add it\n",
        "        # to the layer using `self.add_loss()`.\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "        \n",
        "        # On test time, just return the computed loss\n",
        "        return loss\n",
        "\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    # Inputs to the model\n",
        "    input_img = layers.Input(shape=(img_width, img_height, 1),\n",
        "                            name='input_data',\n",
        "                            dtype='float32')\n",
        "    labels = layers.Input(name='input_label', shape=[max_length], dtype='float32')\n",
        "    input_length = layers.Input(name='input_length', shape=[1], dtype='int64')\n",
        "    label_length = layers.Input(name='label_length', shape=[1], dtype='int64')\n",
        "    \n",
        "    # First conv block\n",
        "\n",
        "    x = layers.Conv2D(64,\n",
        "               (3,3),\n",
        "               activation='relu',\n",
        "               kernel_initializer='he_normal',\n",
        "               padding='same',\n",
        "               name='Conv1')(input_img)\n",
        "    x = layers.MaxPooling2D((2,2), name='pool1')(x)\n",
        "\n",
        "    x = layers.Conv2D(128,\n",
        "               (3,3),\n",
        "               activation='relu',\n",
        "               kernel_initializer='he_normal',\n",
        "               padding='same',\n",
        "               name='Conv2')(x)\n",
        "    x = layers.MaxPooling2D((2,2), name='pool2')(x)\n",
        "    \n",
        "    # Second conv block\n",
        "    x = layers.Conv2D(256,\n",
        "               (3,3),\n",
        "               activation='relu',\n",
        "               kernel_initializer='he_normal',\n",
        "               padding='same',\n",
        "               name='Conv3')(x)\n",
        "    x = layers.MaxPooling2D((2,2), name='pool3')(x)\n",
        "    \n",
        "    # We have used two max pool with pool size and strides of 2.\n",
        "    # Hence, downsampled feature maps are 4x smaller. The number of\n",
        "    # filters in the last layer is 64. Reshape accordingly before\n",
        "    # passing it to RNNs\n",
        "    new_shape = ((img_width // 8), (img_height // 8)*256)\n",
        "    x = layers.Reshape(target_shape=new_shape, name='reshape')(x)\n",
        "    x = layers.Dense(256, activation='relu', name='dense1')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    \n",
        "    # RNNs\n",
        "    x = layers.Bidirectional(layers.LSTM(512,\n",
        "                                         return_sequences=True,\n",
        "                                         dropout=0.2))(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(256,\n",
        "                                         return_sequences=True,\n",
        "                                         dropout=0.25))(x)\n",
        "    \n",
        "    # Predictions\n",
        "    x = layers.Dense(len(characters)+1,\n",
        "              activation='softmax', \n",
        "              name='dense2',\n",
        "              kernel_initializer='he_normal')(x)\n",
        "    \n",
        "    # Calculate CTC\n",
        "    output = CTCLayer(name='ctc_loss')(labels, x, input_length, label_length)\n",
        "    \n",
        "    # Define the model\n",
        "    model = keras.models.Model(inputs=[input_img,\n",
        "                                       labels,\n",
        "                                       input_length,\n",
        "                                       label_length],\n",
        "                                outputs=output,\n",
        "                                name='ocr_model_v1')\n",
        "    \n",
        "    # Optimizer\n",
        "    sgd = keras.optimizers.SGD(learning_rate=0.005,\n",
        "                               decay=1e-6,\n",
        "                               momentum=0.9,\n",
        "                               nesterov=True,\n",
        "                               clipnorm=5)\n",
        "    \n",
        "    # Compile the model and return \n",
        "    model.compile(optimizer=sgd, metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRu0Sc035yAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97f4ae00-be48-443f-cbea-5fc9e2f12370"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'input_length_1:0' shape=(None, 1) dtype=int64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnT8FnnmfDau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep9E7RKLfDXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd466c6e-1fd0-4eee-fb43-cfb1781fa590"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                   patience=200,\n",
        "                                   restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_data_generator,\n",
        "                    validation_data=valid_data_generator,\n",
        "                    epochs=250,\n",
        "                    callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "500/500 [==============================] - 45s 90ms/step - loss: 23.0088 - accuracy: 0.0000e+00 - val_loss: 22.7607 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.7386 - accuracy: 0.0000e+00 - val_loss: 22.6660 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.6503 - accuracy: 0.0000e+00 - val_loss: 22.4731 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.5916 - accuracy: 0.0000e+00 - val_loss: 22.3898 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.3751 - accuracy: 0.0000e+00 - val_loss: 22.3586 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.3189 - accuracy: 0.0000e+00 - val_loss: 22.2960 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2953 - accuracy: 0.0000e+00 - val_loss: 22.2652 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/250\n",
            "500/500 [==============================] - 43s 85ms/step - loss: 22.2817 - accuracy: 0.0000e+00 - val_loss: 22.2734 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2802 - accuracy: 0.0000e+00 - val_loss: 22.2616 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2724 - accuracy: 0.0000e+00 - val_loss: 22.2763 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2675 - accuracy: 0.0000e+00 - val_loss: 22.2375 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2654 - accuracy: 0.0000e+00 - val_loss: 22.2522 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2609 - accuracy: 0.0000e+00 - val_loss: 22.2730 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2637 - accuracy: 0.0000e+00 - val_loss: 22.2720 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2654 - accuracy: 0.0000e+00 - val_loss: 22.2516 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2644 - accuracy: 0.0000e+00 - val_loss: 22.2709 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2672 - accuracy: 0.0000e+00 - val_loss: 22.2369 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2650 - accuracy: 0.0000e+00 - val_loss: 22.2672 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2749 - accuracy: 0.0000e+00 - val_loss: 22.2387 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2750 - accuracy: 0.0000e+00 - val_loss: 22.3221 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2666 - accuracy: 0.0000e+00 - val_loss: 22.2466 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2614 - accuracy: 0.0000e+00 - val_loss: 22.2572 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2673 - accuracy: 0.0000e+00 - val_loss: 22.2643 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2556 - accuracy: 0.0000e+00 - val_loss: 22.2391 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2593 - accuracy: 0.0000e+00 - val_loss: 22.2619 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2631 - accuracy: 0.0000e+00 - val_loss: 22.2422 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2577 - accuracy: 0.0000e+00 - val_loss: 22.2335 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2612 - accuracy: 0.0000e+00 - val_loss: 22.2530 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2566 - accuracy: 0.0000e+00 - val_loss: 22.2868 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2645 - accuracy: 0.0000e+00 - val_loss: 22.2470 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2532 - accuracy: 0.0000e+00 - val_loss: 22.2520 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2497 - accuracy: 0.0000e+00 - val_loss: 22.2481 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2522 - accuracy: 0.0000e+00 - val_loss: 22.2233 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2486 - accuracy: 0.0000e+00 - val_loss: 22.2316 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2470 - accuracy: 0.0000e+00 - val_loss: 22.2523 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2461 - accuracy: 0.0000e+00 - val_loss: 22.2459 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2475 - accuracy: 0.0000e+00 - val_loss: 22.2403 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2458 - accuracy: 0.0000e+00 - val_loss: 22.2334 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2487 - accuracy: 0.0000e+00 - val_loss: 22.2418 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2404 - accuracy: 0.0000e+00 - val_loss: 22.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2427 - accuracy: 0.0000e+00 - val_loss: 22.2388 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2431 - accuracy: 0.0000e+00 - val_loss: 22.2214 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2441 - accuracy: 0.0000e+00 - val_loss: 22.2487 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2469 - accuracy: 0.0000e+00 - val_loss: 22.2454 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2439 - accuracy: 0.0000e+00 - val_loss: 22.2478 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2410 - accuracy: 0.0000e+00 - val_loss: 22.2251 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2424 - accuracy: 0.0000e+00 - val_loss: 22.2540 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/250\n",
            "500/500 [==============================] - 43s 85ms/step - loss: 22.2412 - accuracy: 0.0000e+00 - val_loss: 22.2486 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2444 - accuracy: 0.0000e+00 - val_loss: 22.2306 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2416 - accuracy: 0.0000e+00 - val_loss: 22.2216 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2423 - accuracy: 0.0000e+00 - val_loss: 22.2568 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2434 - accuracy: 0.0000e+00 - val_loss: 22.2294 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2434 - accuracy: 0.0000e+00 - val_loss: 22.2356 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2424 - accuracy: 0.0000e+00 - val_loss: 22.2525 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2425 - accuracy: 0.0000e+00 - val_loss: 22.2316 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2447 - accuracy: 0.0000e+00 - val_loss: 22.2307 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2400 - accuracy: 0.0000e+00 - val_loss: 22.2386 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2431 - accuracy: 0.0000e+00 - val_loss: 22.2183 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2430 - accuracy: 0.0000e+00 - val_loss: 22.2389 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2420 - accuracy: 0.0000e+00 - val_loss: 22.2403 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2429 - accuracy: 0.0000e+00 - val_loss: 22.2418 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2422 - accuracy: 0.0000e+00 - val_loss: 22.2206 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2395 - accuracy: 0.0000e+00 - val_loss: 22.2195 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2401 - accuracy: 0.0000e+00 - val_loss: 22.2315 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2383 - accuracy: 0.0000e+00 - val_loss: 22.2313 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2421 - accuracy: 0.0000e+00 - val_loss: 22.2327 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2415 - accuracy: 0.0000e+00 - val_loss: 22.2295 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2388 - accuracy: 0.0000e+00 - val_loss: 22.2255 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2401 - accuracy: 0.0000e+00 - val_loss: 22.2472 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2398 - accuracy: 0.0000e+00 - val_loss: 22.2384 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2393 - accuracy: 0.0000e+00 - val_loss: 22.2530 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2407 - accuracy: 0.0000e+00 - val_loss: 22.2434 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2377 - accuracy: 0.0000e+00 - val_loss: 22.2513 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/250\n",
            "500/500 [==============================] - 41s 83ms/step - loss: 22.2397 - accuracy: 0.0000e+00 - val_loss: 22.2411 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2430 - accuracy: 0.0000e+00 - val_loss: 22.2288 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2358 - accuracy: 0.0000e+00 - val_loss: 22.2240 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2398 - accuracy: 0.0000e+00 - val_loss: 22.2316 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2376 - accuracy: 0.0000e+00 - val_loss: 22.2380 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2404 - accuracy: 0.0000e+00 - val_loss: 22.2407 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2402 - accuracy: 0.0000e+00 - val_loss: 22.2437 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2421 - accuracy: 0.0000e+00 - val_loss: 22.2512 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2390 - accuracy: 0.0000e+00 - val_loss: 22.2453 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2368 - accuracy: 0.0000e+00 - val_loss: 22.2457 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/250\n",
            "500/500 [==============================] - 43s 87ms/step - loss: 22.2395 - accuracy: 0.0000e+00 - val_loss: 22.2357 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2372 - accuracy: 0.0000e+00 - val_loss: 22.2269 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2388 - accuracy: 0.0000e+00 - val_loss: 22.2150 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2393 - accuracy: 0.0000e+00 - val_loss: 22.2322 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2401 - accuracy: 0.0000e+00 - val_loss: 22.2497 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2345 - accuracy: 0.0000e+00 - val_loss: 22.2186 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2392 - accuracy: 0.0000e+00 - val_loss: 22.2691 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/250\n",
            "500/500 [==============================] - 43s 85ms/step - loss: 22.2411 - accuracy: 0.0000e+00 - val_loss: 22.2169 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/250\n",
            "500/500 [==============================] - 43s 86ms/step - loss: 22.2433 - accuracy: 0.0000e+00 - val_loss: 22.2458 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2369 - accuracy: 0.0000e+00 - val_loss: 22.2363 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2416 - accuracy: 0.0000e+00 - val_loss: 22.2479 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2377 - accuracy: 0.0000e+00 - val_loss: 22.2344 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2425 - accuracy: 0.0000e+00 - val_loss: 22.2374 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2382 - accuracy: 0.0000e+00 - val_loss: 22.2416 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2400 - accuracy: 0.0000e+00 - val_loss: 22.2341 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2359 - accuracy: 0.0000e+00 - val_loss: 22.2335 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/250\n",
            "500/500 [==============================] - 43s 86ms/step - loss: 22.2412 - accuracy: 0.0000e+00 - val_loss: 22.2386 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/250\n",
            "500/500 [==============================] - 43s 85ms/step - loss: 22.2379 - accuracy: 0.0000e+00 - val_loss: 22.2318 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/250\n",
            "500/500 [==============================] - 44s 87ms/step - loss: 22.2351 - accuracy: 0.0000e+00 - val_loss: 22.2466 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2402 - accuracy: 0.0000e+00 - val_loss: 22.2476 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/250\n",
            "500/500 [==============================] - 43s 85ms/step - loss: 22.2381 - accuracy: 0.0000e+00 - val_loss: 22.2438 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2398 - accuracy: 0.0000e+00 - val_loss: 22.2269 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/250\n",
            "500/500 [==============================] - 43s 86ms/step - loss: 22.2378 - accuracy: 0.0000e+00 - val_loss: 22.2331 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2386 - accuracy: 0.0000e+00 - val_loss: 22.2373 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2411 - accuracy: 0.0000e+00 - val_loss: 22.2458 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2395 - accuracy: 0.0000e+00 - val_loss: 22.2303 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2412 - accuracy: 0.0000e+00 - val_loss: 22.2467 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2411 - accuracy: 0.0000e+00 - val_loss: 22.2455 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2410 - accuracy: 0.0000e+00 - val_loss: 22.2324 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2381 - accuracy: 0.0000e+00 - val_loss: 22.2253 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/250\n",
            "500/500 [==============================] - 43s 86ms/step - loss: 22.2416 - accuracy: 0.0000e+00 - val_loss: 22.2506 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2421 - accuracy: 0.0000e+00 - val_loss: 22.2523 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2435 - accuracy: 0.0000e+00 - val_loss: 22.2382 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2403 - accuracy: 0.0000e+00 - val_loss: 22.2373 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2420 - accuracy: 0.0000e+00 - val_loss: 22.2394 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2449 - accuracy: 0.0000e+00 - val_loss: 22.2369 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2362 - accuracy: 0.0000e+00 - val_loss: 22.2534 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2367 - accuracy: 0.0000e+00 - val_loss: 22.2318 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2367 - accuracy: 0.0000e+00 - val_loss: 22.2344 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2327 - accuracy: 0.0000e+00 - val_loss: 22.2265 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2371 - accuracy: 0.0000e+00 - val_loss: 22.2342 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2332 - accuracy: 0.0000e+00 - val_loss: 22.2360 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2338 - accuracy: 0.0000e+00 - val_loss: 22.2371 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2349 - accuracy: 0.0000e+00 - val_loss: 22.2362 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/250\n",
            "500/500 [==============================] - 43s 85ms/step - loss: 22.2308 - accuracy: 0.0000e+00 - val_loss: 22.2387 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2361 - accuracy: 0.0000e+00 - val_loss: 22.2365 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2368 - accuracy: 0.0000e+00 - val_loss: 22.2297 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2381 - accuracy: 0.0000e+00 - val_loss: 22.2234 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/250\n",
            "500/500 [==============================] - 43s 85ms/step - loss: 22.2374 - accuracy: 0.0000e+00 - val_loss: 22.2400 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2348 - accuracy: 0.0000e+00 - val_loss: 22.2220 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2334 - accuracy: 0.0000e+00 - val_loss: 22.2507 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2384 - accuracy: 0.0000e+00 - val_loss: 22.2268 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2353 - accuracy: 0.0000e+00 - val_loss: 22.2588 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2380 - accuracy: 0.0000e+00 - val_loss: 22.2570 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2354 - accuracy: 0.0000e+00 - val_loss: 22.2388 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2353 - accuracy: 0.0000e+00 - val_loss: 22.2339 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2364 - accuracy: 0.0000e+00 - val_loss: 22.2082 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2369 - accuracy: 0.0000e+00 - val_loss: 22.2439 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2336 - accuracy: 0.0000e+00 - val_loss: 22.2257 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/250\n",
            "500/500 [==============================] - 43s 85ms/step - loss: 22.2364 - accuracy: 0.0000e+00 - val_loss: 22.2369 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/250\n",
            "500/500 [==============================] - 43s 85ms/step - loss: 22.2368 - accuracy: 0.0000e+00 - val_loss: 22.2242 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2355 - accuracy: 0.0000e+00 - val_loss: 22.2562 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2372 - accuracy: 0.0000e+00 - val_loss: 22.2340 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2361 - accuracy: 0.0000e+00 - val_loss: 22.2466 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2381 - accuracy: 0.0000e+00 - val_loss: 22.2191 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2403 - accuracy: 0.0000e+00 - val_loss: 22.2510 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2406 - accuracy: 0.0000e+00 - val_loss: 22.2416 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2392 - accuracy: 0.0000e+00 - val_loss: 22.2463 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2346 - accuracy: 0.0000e+00 - val_loss: 22.2392 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2396 - accuracy: 0.0000e+00 - val_loss: 22.2338 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2423 - accuracy: 0.0000e+00 - val_loss: 22.2449 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2411 - accuracy: 0.0000e+00 - val_loss: 22.2401 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2394 - accuracy: 0.0000e+00 - val_loss: 22.2591 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2389 - accuracy: 0.0000e+00 - val_loss: 22.2231 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2368 - accuracy: 0.0000e+00 - val_loss: 22.2451 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2424 - accuracy: 0.0000e+00 - val_loss: 22.2294 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2431 - accuracy: 0.0000e+00 - val_loss: 22.2340 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2402 - accuracy: 0.0000e+00 - val_loss: 22.2295 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2413 - accuracy: 0.0000e+00 - val_loss: 22.2308 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2448 - accuracy: 0.0000e+00 - val_loss: 22.2563 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2443 - accuracy: 0.0000e+00 - val_loss: 22.2540 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2458 - accuracy: 0.0000e+00 - val_loss: 22.2364 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2398 - accuracy: 0.0000e+00 - val_loss: 22.2345 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2483 - accuracy: 0.0000e+00 - val_loss: 22.2312 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2466 - accuracy: 0.0000e+00 - val_loss: 22.2283 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2387 - accuracy: 0.0000e+00 - val_loss: 22.2519 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2422 - accuracy: 0.0000e+00 - val_loss: 22.2311 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2374 - accuracy: 0.0000e+00 - val_loss: 22.2386 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2403 - accuracy: 0.0000e+00 - val_loss: 22.2409 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2372 - accuracy: 0.0000e+00 - val_loss: 22.2407 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2322 - accuracy: 0.0000e+00 - val_loss: 22.2446 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2347 - accuracy: 0.0000e+00 - val_loss: 22.2264 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2327 - accuracy: 0.0000e+00 - val_loss: 22.2387 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2331 - accuracy: 0.0000e+00 - val_loss: 22.2320 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2322 - accuracy: 0.0000e+00 - val_loss: 22.2195 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2317 - accuracy: 0.0000e+00 - val_loss: 22.2260 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2301 - accuracy: 0.0000e+00 - val_loss: 22.2310 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 22.2312 - accuracy: 0.0000e+00 - val_loss: 22.2295 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2299 - accuracy: 0.0000e+00 - val_loss: 22.2518 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2311 - accuracy: 0.0000e+00 - val_loss: 22.2172 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2286 - accuracy: 0.0000e+00 - val_loss: 22.2390 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2296 - accuracy: 0.0000e+00 - val_loss: 22.2331 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/250\n",
            "500/500 [==============================] - 43s 85ms/step - loss: 22.2282 - accuracy: 0.0000e+00 - val_loss: 22.2399 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2299 - accuracy: 0.0000e+00 - val_loss: 22.2417 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2291 - accuracy: 0.0000e+00 - val_loss: 22.2159 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2274 - accuracy: 0.0000e+00 - val_loss: 22.2478 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/250\n",
            "500/500 [==============================] - 43s 85ms/step - loss: 22.2305 - accuracy: 0.0000e+00 - val_loss: 22.2216 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2245 - accuracy: 0.0000e+00 - val_loss: 22.2197 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2261 - accuracy: 0.0000e+00 - val_loss: 22.2449 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2273 - accuracy: 0.0000e+00 - val_loss: 22.2358 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 22.2248 - accuracy: 0.0000e+00 - val_loss: 22.2197 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.2260 - accuracy: 0.0000e+00 - val_loss: 22.2271 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 22.1942 - accuracy: 0.0000e+00 - val_loss: 22.0160 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 21.2397 - accuracy: 0.0000e+00 - val_loss: 19.9088 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 17.9771 - accuracy: 0.0000e+00 - val_loss: 15.8815 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 13.2035 - accuracy: 0.0000e+00 - val_loss: 9.0711 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 7.1015 - accuracy: 0.0044 - val_loss: 3.1277 - val_accuracy: 0.0885\n",
            "Epoch 201/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 2.9450 - accuracy: 0.1306 - val_loss: 1.9535 - val_accuracy: 0.3732\n",
            "Epoch 202/250\n",
            "500/500 [==============================] - 43s 85ms/step - loss: 1.9834 - accuracy: 0.3172 - val_loss: 1.5291 - val_accuracy: 0.5153\n",
            "Epoch 203/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 1.4956 - accuracy: 0.4617 - val_loss: 1.2933 - val_accuracy: 0.5768\n",
            "Epoch 204/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 1.2271 - accuracy: 0.5430 - val_loss: 1.1035 - val_accuracy: 0.6363\n",
            "Epoch 205/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 1.0586 - accuracy: 0.5956 - val_loss: 1.1685 - val_accuracy: 0.6663\n",
            "Epoch 206/250\n",
            "500/500 [==============================] - 43s 86ms/step - loss: 0.9552 - accuracy: 0.6353 - val_loss: 1.0325 - val_accuracy: 0.7054\n",
            "Epoch 207/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.8021 - accuracy: 0.6876 - val_loss: 1.2042 - val_accuracy: 0.6733\n",
            "Epoch 208/250\n",
            "500/500 [==============================] - 43s 85ms/step - loss: 0.7366 - accuracy: 0.7127 - val_loss: 0.9674 - val_accuracy: 0.7264\n",
            "Epoch 209/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 0.6603 - accuracy: 0.7416 - val_loss: 1.0600 - val_accuracy: 0.7129\n",
            "Epoch 210/250\n",
            "500/500 [==============================] - 43s 87ms/step - loss: 0.5929 - accuracy: 0.7645 - val_loss: 0.9471 - val_accuracy: 0.7484\n",
            "Epoch 211/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 0.5814 - accuracy: 0.7774 - val_loss: 0.9190 - val_accuracy: 0.7539\n",
            "Epoch 212/250\n",
            "500/500 [==============================] - 43s 85ms/step - loss: 0.5335 - accuracy: 0.7914 - val_loss: 1.1117 - val_accuracy: 0.7134\n",
            "Epoch 213/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.5115 - accuracy: 0.7942 - val_loss: 1.0288 - val_accuracy: 0.7459\n",
            "Epoch 214/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.4513 - accuracy: 0.8178 - val_loss: 0.9721 - val_accuracy: 0.7664\n",
            "Epoch 215/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.4399 - accuracy: 0.8243 - val_loss: 0.9791 - val_accuracy: 0.7629\n",
            "Epoch 216/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 0.3882 - accuracy: 0.8426 - val_loss: 1.0727 - val_accuracy: 0.7549\n",
            "Epoch 217/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 0.4072 - accuracy: 0.8381 - val_loss: 1.0221 - val_accuracy: 0.7664\n",
            "Epoch 218/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.3862 - accuracy: 0.8481 - val_loss: 1.0845 - val_accuracy: 0.7509\n",
            "Epoch 219/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.3675 - accuracy: 0.8556 - val_loss: 1.0034 - val_accuracy: 0.7899\n",
            "Epoch 220/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.3558 - accuracy: 0.8565 - val_loss: 0.9847 - val_accuracy: 0.7904\n",
            "Epoch 221/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.3282 - accuracy: 0.8701 - val_loss: 0.9730 - val_accuracy: 0.7954\n",
            "Epoch 222/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 0.3443 - accuracy: 0.8728 - val_loss: 1.4662 - val_accuracy: 0.7354\n",
            "Epoch 223/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.3272 - accuracy: 0.8743 - val_loss: 0.9989 - val_accuracy: 0.7939\n",
            "Epoch 224/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 0.3348 - accuracy: 0.8746 - val_loss: 1.0551 - val_accuracy: 0.7844\n",
            "Epoch 225/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.3010 - accuracy: 0.8859 - val_loss: 0.9914 - val_accuracy: 0.7939\n",
            "Epoch 226/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2996 - accuracy: 0.8888 - val_loss: 1.0764 - val_accuracy: 0.7869\n",
            "Epoch 227/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2954 - accuracy: 0.8840 - val_loss: 1.0185 - val_accuracy: 0.7899\n",
            "Epoch 228/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2945 - accuracy: 0.8932 - val_loss: 0.9935 - val_accuracy: 0.8084\n",
            "Epoch 229/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2941 - accuracy: 0.8913 - val_loss: 1.0296 - val_accuracy: 0.8039\n",
            "Epoch 230/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2930 - accuracy: 0.8889 - val_loss: 1.0284 - val_accuracy: 0.8084\n",
            "Epoch 231/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2928 - accuracy: 0.8899 - val_loss: 1.0377 - val_accuracy: 0.7899\n",
            "Epoch 232/250\n",
            "500/500 [==============================] - 43s 86ms/step - loss: 0.2663 - accuracy: 0.9004 - val_loss: 1.1330 - val_accuracy: 0.7969\n",
            "Epoch 233/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2533 - accuracy: 0.9052 - val_loss: 1.2115 - val_accuracy: 0.7789\n",
            "Epoch 234/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 0.2636 - accuracy: 0.9048 - val_loss: 1.2681 - val_accuracy: 0.7779\n",
            "Epoch 235/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2937 - accuracy: 0.8937 - val_loss: 1.1987 - val_accuracy: 0.7849\n",
            "Epoch 236/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2723 - accuracy: 0.8954 - val_loss: 1.2547 - val_accuracy: 0.7844\n",
            "Epoch 237/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 0.2538 - accuracy: 0.9040 - val_loss: 1.0983 - val_accuracy: 0.7909\n",
            "Epoch 238/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2637 - accuracy: 0.8995 - val_loss: 1.1286 - val_accuracy: 0.7964\n",
            "Epoch 239/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2440 - accuracy: 0.9065 - val_loss: 1.1136 - val_accuracy: 0.7994\n",
            "Epoch 240/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2758 - accuracy: 0.8985 - val_loss: 1.0854 - val_accuracy: 0.8049\n",
            "Epoch 241/250\n",
            "500/500 [==============================] - 42s 83ms/step - loss: 0.2598 - accuracy: 0.9027 - val_loss: 1.2144 - val_accuracy: 0.7909\n",
            "Epoch 242/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2455 - accuracy: 0.9102 - val_loss: 1.1124 - val_accuracy: 0.8034\n",
            "Epoch 243/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2517 - accuracy: 0.9088 - val_loss: 1.2452 - val_accuracy: 0.7794\n",
            "Epoch 244/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2863 - accuracy: 0.8963 - val_loss: 1.3617 - val_accuracy: 0.7774\n",
            "Epoch 245/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2598 - accuracy: 0.9074 - val_loss: 1.3276 - val_accuracy: 0.7554\n",
            "Epoch 246/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 0.2887 - accuracy: 0.8969 - val_loss: 1.2096 - val_accuracy: 0.7974\n",
            "Epoch 247/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2822 - accuracy: 0.8999 - val_loss: 1.2504 - val_accuracy: 0.7864\n",
            "Epoch 248/250\n",
            "500/500 [==============================] - 43s 85ms/step - loss: 0.2610 - accuracy: 0.9073 - val_loss: 1.2020 - val_accuracy: 0.7884\n",
            "Epoch 249/250\n",
            "500/500 [==============================] - 42s 84ms/step - loss: 0.2488 - accuracy: 0.9097 - val_loss: 1.0777 - val_accuracy: 0.7959\n",
            "Epoch 250/250\n",
            "500/500 [==============================] - 42s 85ms/step - loss: 0.2631 - accuracy: 0.9044 - val_loss: 1.2240 - val_accuracy: 0.7934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI7aKU4YfDTw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "3eb0dd6b-da3c-4f07-fec2-a03b78211dd7"
      },
      "source": [
        "prediction_model = keras.models.Model(model.get_layer(name='input_data').input,\n",
        "                                        model.get_layer(name='dense2').output)\n",
        "prediction_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_data (InputLayer)      [(None, 150, 50, 1)]      0         \n",
            "_________________________________________________________________\n",
            "Conv1 (Conv2D)               (None, 150, 50, 64)       640       \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 75, 25, 64)        0         \n",
            "_________________________________________________________________\n",
            "Conv2 (Conv2D)               (None, 75, 25, 128)       73856     \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 37, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "Conv3 (Conv2D)               (None, 37, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "pool3 (MaxPooling2D)         (None, 18, 6, 256)        0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 18, 1536)          0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 18, 256)           393472    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 18, 256)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 18, 1024)          3149824   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 18, 512)           2623488   \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 18, 37)            18981     \n",
            "=================================================================\n",
            "Total params: 6,555,429\n",
            "Trainable params: 6,555,429\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR89hlhbWrAc",
        "colab_type": "text"
      },
      "source": [
        "# Prediction Decode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HDhueDQfDQR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A utility to decode the output of the network\n",
        "def decode_batch_predictions(pred):\n",
        "    pred = pred[:, :-2]\n",
        "    input_len = np.ones(pred.shape[0])*pred.shape[1]\n",
        "    \n",
        "    # Use greedy search. For complex tasks, you can use beam search\n",
        "    results = keras.backend.ctc_decode(pred, \n",
        "                                        input_length=input_len,\n",
        "                                        greedy=True)[0][0]\n",
        "    \n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for res in results.numpy():\n",
        "        outstr = ''\n",
        "        for c in res:\n",
        "            if c < len(characters) and c >=0:\n",
        "                outstr += labels_to_char[c]\n",
        "        output_text.append(outstr)\n",
        "    \n",
        "    # return final text results\n",
        "    return output_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "macexRmkEtQs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "036d2709-cfcf-4149-e9fd-7058dc4c1548"
      },
      "source": [
        "#  Let's check results on some validation samples\n",
        "for p, (inp_value, _) in enumerate(valid_data_generator):\n",
        "    bs = inp_value['input_data'].shape[0]\n",
        "    X_data = inp_value['input_data']\n",
        "    print(X_data.shape)\n",
        "    labels = inp_value['input_label']\n",
        "    print(labels.shape)\n",
        "\n",
        "    preds = prediction_model.predict(X_data)\n",
        "    pred_texts = decode_batch_predictions(preds)\n",
        "    \n",
        "    orig_texts = []\n",
        "    for label in labels:\n",
        "        text = ''.join([labels_to_char[int(x)] for x in label])\n",
        "        orig_texts.append(text)\n",
        "        \n",
        "    for i in range(bs):\n",
        "        print(f'Ground truth: {orig_texts[i]} \\t Predicted: {pred_texts[i]}')\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16, 150, 50, 1)\n",
            "(16, 6)\n",
            "Ground truth: 7t41zr \t Predicted: 7t41zr\n",
            "Ground truth: bkovqu \t Predicted: bkovqu\n",
            "Ground truth: t4a3t8 \t Predicted: t4a3t8\n",
            "Ground truth: x1jv6a \t Predicted: x1sv6a\n",
            "Ground truth: ku7jov \t Predicted: ku7jov\n",
            "Ground truth: wp8h3j \t Predicted: wp8h3j\n",
            "Ground truth: rlnoxq \t Predicted: rlnoxq\n",
            "Ground truth: 0s48tm \t Predicted: 0s48tm\n",
            "Ground truth: 4yc6fu \t Predicted: 4yc6fu\n",
            "Ground truth: spfj96 \t Predicted: spfj96\n",
            "Ground truth: fnuh4b \t Predicted: fnuh4b\n",
            "Ground truth: a9ody1 \t Predicted: a9ody1\n",
            "Ground truth: 07w96p \t Predicted: 07w96p\n",
            "Ground truth: ooequ6 \t Predicted: ooequ6\n",
            "Ground truth: 9hhqaa \t Predicted: 9hhqaa\n",
            "Ground truth: 9mh0br \t Predicted: 9mh0br\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYMOPFl5EtUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size=len(validation_labels)\n",
        "curr_idx=np.arange(size)\n",
        "\n",
        "X = np.ones((size, 150, 50, 1),dtype=np.float32)\n",
        "Y = np.ones((size, 6), dtype=np.float32)\n",
        "# input_length = np.ones((batch_len, 1), dtype=np.int64) * \\\n",
        "#                         (self.img_width // self.downsample_factor - 2)\n",
        "# label_length = np.zeros((batch_len, 1), dtype=np.int64)\n",
        "\n",
        "for j, idx in enumerate(curr_idx):\n",
        "  # 1. Get the image and transpose it\n",
        "  img = validation_data[idx].T\n",
        "  # 2. Add extra dimenison\n",
        "  img = np.expand_dims(img, axis=-1)\n",
        "  # 3. Get the correpsonding label\n",
        "  text = validation_labels[idx]\n",
        "  # 4. Include the pair only if the captcha is valid\n",
        "  if is_valid_captcha(text):\n",
        "    label = [char_to_labels[ch] for ch in text]\n",
        "    X[j] = img\n",
        "    Y[j] = label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfuJLgiBBlqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_eval(x,y,model):\n",
        "\n",
        "  preds=model.predict(x)\n",
        "  pred_texts=decode_batch_predictions(preds)\n",
        "  cnt=0\n",
        "  orig_texts = []\n",
        "  for label in y:\n",
        "      text = ''.join([labels_to_char[int(x)] for x in label])\n",
        "      orig_texts.append(text)\n",
        "  \n",
        "  for i in range(len(y)):\n",
        "    if pred_texts[i]==orig_texts[i]:\n",
        "      cnt=cnt+1\n",
        "  print(cnt)\n",
        "  return cnt/len(pred_texts)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFrrgR4h8vn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiRpys8OWTnk",
        "colab_type": "text"
      },
      "source": [
        "# Test Data Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jFNEgoS8vqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "bcf40d5a-042a-42d4-ec4a-47c28037b3de"
      },
      "source": [
        "dir = \"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/newtestcaptcha/\"\n",
        "os.chdir(dir)\n",
        "# data_dir = Path(\"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/data/\")\n",
        "\n",
        "# Get list of all the images\n",
        "# images = list(data_dir.glob(\"*.png\"))\n",
        "images = os.listdir(dir)\n",
        "print(\"Number of images found: \", len(images))\n",
        "\n",
        "# Let's take a look at some samples first. \n",
        "# Always look at your data!\n",
        "\n",
        "_,ax = plt.subplots(2,2, figsize=(5,3))\n",
        "for i in range(4):\n",
        "    img = cv2.imread(images[i])\n",
        "    # img = cv2.imread(images[i])\n",
        "    # plt.imshow(img)\n",
        "    print(\"Shape of image: \", img.shape)\n",
        "    ax[i//2, i%2].imshow(img)\n",
        "    ax[i//2, i%2].axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images found:  2000\n",
            "Shape of image:  (50, 150, 3)\n",
            "Shape of image:  (50, 150, 3)\n",
            "Shape of image:  (50, 150, 3)\n",
            "Shape of image:  (50, 150, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x216 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFgpkoJw9Ycp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "6f9dc677-2193-4600-d703-6181a44acf24"
      },
      "source": [
        "# Store all the characters in a set\n",
        "characters = set()\n",
        "\n",
        "# A list to store the length of each captcha\n",
        "captcha_length = []\n",
        "\n",
        "# Store image-label info\n",
        "dataset = []\n",
        "\n",
        "# Iterate over the dataset and store the\n",
        "# information needed\n",
        "for img_path in images:\n",
        "    # 1. Get the label associated with each image\n",
        "    label = img_path.split(\".\")[0]\n",
        "    if len(label)!=6:\n",
        "      continue\n",
        "\n",
        "    # 2. Store the length of this cpatcha\n",
        "    captcha_length.append(len(label))\n",
        "    # 3. Store the image-label pair info\n",
        "    dataset.append((str(img_path), label))\n",
        "    \n",
        "    # 4. Store the characters present\n",
        "    for ch in label:\n",
        "        characters.add(ch)\n",
        "\n",
        "# Sort the characters        \n",
        "characters = sorted(characters)\n",
        "\n",
        "# Convert the dataset info into a dataframe\n",
        "dataset = pd.DataFrame(dataset, columns=[\"img_path\", \"label\"], index=None)\n",
        "\n",
        "# Shuffle the dataset\n",
        "dataset = dataset.sample(frac=1.).reset_index(drop=True)\n",
        "test_data= dataset.copy()\n",
        "\n",
        "print(\"Number of unqiue charcaters in the whole dataset: \", len(characters))\n",
        "print(\"Maximum length of any captcha: \", max(Counter(captcha_length).keys()))\n",
        "print(\"Characters present: \", characters)\n",
        "print(\"Total number of samples in the dataset: \", len(dataset))\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unqiue charcaters in the whole dataset:  36\n",
            "Maximum length of any captcha:  6\n",
            "Characters present:  ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "Total number of samples in the dataset:  2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>k4hp5c.png</td>\n",
              "      <td>k4hp5c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>j5uusm.png</td>\n",
              "      <td>j5uusm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cz87rl.png</td>\n",
              "      <td>cz87rl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ymc56i.png</td>\n",
              "      <td>ymc56i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>n0hlv2.png</td>\n",
              "      <td>n0hlv2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     img_path   label\n",
              "0  k4hp5c.png  k4hp5c\n",
              "1  j5uusm.png  j5uusm\n",
              "2  cz87rl.png  cz87rl\n",
              "3  ymc56i.png  ymc56i\n",
              "4  n0hlv2.png  n0hlv2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ng8Nl8wX9Ynp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5bfc64d8-ff76-4d2e-9a51-89271323b106"
      },
      "source": [
        "# Map text to numeric labels \n",
        "char_to_labels = {char:idx for idx, char in enumerate(characters)}\n",
        "\n",
        "# Map numeric labels to text\n",
        "labels_to_char = {val:key for key, val in char_to_labels.items()}\n",
        "\n",
        "# Sanity check for corrupted images\n",
        "def is_valid_captcha(captcha):\n",
        "    for ch in captcha:\n",
        "        if not ch in characters:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "# Store arrays in memory as it's not a muvh big dataset\n",
        "def generate_arrays(df, resize=True, img_height=img.shape[0], img_width=img.shape[1]):\n",
        "    \"\"\"Generates image array and labels array from a dataframe.\n",
        "    \n",
        "    Args:\n",
        "        df: dataframe from which we want to read the data\n",
        "        resize (bool)    : whether to resize images or not\n",
        "        img_weidth (int): width of the resized images\n",
        "        img_height (int): height of the resized images\n",
        "        \n",
        "    Returns:\n",
        "        images (ndarray): grayscale images\n",
        "        labels (ndarray): corresponding encoded labels\n",
        "    \"\"\"\n",
        "    \n",
        "    num_items = len(df)\n",
        "    images = np.zeros((num_items, img_height, img_width), dtype=np.float32)\n",
        "    labels = [0]*num_items\n",
        "    \n",
        "    for i in range(num_items):\n",
        "        img = cv2.imread(df[\"img_path\"][i])\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        if resize: \n",
        "            img = cv2.resize(img, (img_width, img_height))\n",
        "        \n",
        "        img = (img/255.).astype(np.float32)\n",
        "        label = df[\"label\"][i]\n",
        "        \n",
        "        # Add only if it is a valid captcha\n",
        "        if is_valid_captcha(label):\n",
        "            images[i, :, :] = img\n",
        "            labels[i] = label\n",
        "    \n",
        "    return images, np.array(labels)\n",
        "\n",
        "# Build training data\n",
        "test_data, test_labels = generate_arrays(df=test_data)\n",
        "print(\"Number of test images: \", test_data.shape)\n",
        "print(\"Number of test labels: \", test_labels.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test images:  (2000, 50, 150)\n",
            "Number of test labels:  (2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjC-PAK89YrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    \"\"\"Generates batches from a given dataset.\n",
        "    \n",
        "    Args:\n",
        "        data: training or validation data\n",
        "        labels: corresponding labels\n",
        "        char_map: dictionary mapping char to labels\n",
        "        batch_size: size of a single batch\n",
        "        img_width: width of the resized\n",
        "        img_height: height of the resized\n",
        "        downsample_factor: by what factor did the CNN downsample the images\n",
        "        max_length: maximum length of any captcha\n",
        "        shuffle: whether to shuffle data or not after each epoch\n",
        "    Returns:\n",
        "        batch_inputs: a dictionary containing batch inputs \n",
        "        batch_labels: a batch of corresponding labels \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self,\n",
        "                 data,\n",
        "                 labels,\n",
        "                 char_map,\n",
        "                 batch_size,\n",
        "                 img_width,\n",
        "                 img_height,\n",
        "                 downsample_factor,\n",
        "                 max_length,\n",
        "                 shuffle=True\n",
        "                ):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "        self.char_map = char_map\n",
        "        self.batch_size = batch_size\n",
        "        self.img_width = img_width\n",
        "        self.img_height = img_height\n",
        "        self.downsample_factor = downsample_factor\n",
        "        self.max_length = max_length\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(data))    \n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.data) / self.batch_size))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # 1. Get the next batch indices\n",
        "        curr_batch_idx = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
        "        \n",
        "        # 2. This isn't necessary but it can help us save some memory\n",
        "        # as not all batches the last batch may not have elements\n",
        "        # equal to the batch_size \n",
        "        batch_len = len(curr_batch_idx)\n",
        "        \n",
        "        # 3. Instantiate batch arrays\n",
        "        batch_images = np.ones((batch_len, self.img_width, self.img_height, 1),\n",
        "                               dtype=np.float32)\n",
        "        batch_labels = np.ones((batch_len, self.max_length), dtype=np.float32)\n",
        "        input_length = np.ones((batch_len, 1), dtype=np.int64) * \\\n",
        "                                (self.img_width // self.downsample_factor)\n",
        "        label_length = np.zeros((batch_len, 1), dtype=np.int64)\n",
        "        \n",
        "        \n",
        "        for j, idx in enumerate(curr_batch_idx):\n",
        "            # 1. Get the image and transpose it\n",
        "            img = self.data[idx].T\n",
        "            # 2. Add extra dimenison\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "            # 3. Get the correpsonding label\n",
        "            text = self.labels[idx]\n",
        "            # 4. Include the pair only if the captcha is valid\n",
        "            if is_valid_captcha(text):\n",
        "                label = [self.char_map[ch] for ch in text]\n",
        "                batch_images[j] = img\n",
        "                batch_labels[j] = label\n",
        "                label_length[j] = len(text)\n",
        "        \n",
        "        batch_inputs = {\n",
        "                'input_data': batch_images,\n",
        "                'input_label': batch_labels,\n",
        "                'input_length': input_length,\n",
        "                'label_length': label_length,\n",
        "                }\n",
        "        return batch_inputs, np.zeros(batch_len).astype(np.float32)\n",
        "        \n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL_eRkRT9YvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Batch size for training and validation\n",
        "batch_size = 16\n",
        "\n",
        "# Desired image dimensions\n",
        "img_width=img.shape[1]\n",
        "img_height=img.shape[0]\n",
        "\n",
        "# Factor  by which the image is going to be downsampled\n",
        "# by the convolutional blocks\n",
        "downsample_factor=8\n",
        "\n",
        "# Maximum length of any captcha in the data\n",
        "max_length=6\n",
        "\n",
        "# Get a generator object for the training data\n",
        "test_data_generator = DataGenerator(data=test_data,\n",
        "                                     labels=test_labels,\n",
        "                                     char_map=char_to_labels,\n",
        "                                     batch_size=batch_size,\n",
        "                                     img_width=img_width,\n",
        "                                     img_height=img_height,\n",
        "                                     downsample_factor=downsample_factor,\n",
        "                                     max_length=max_length,\n",
        "                                     shuffle=True\n",
        "                                    )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1MS797p9Y0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size=len(test_labels)\n",
        "curr_idx=np.arange(size)\n",
        "\n",
        "X = np.ones((size, 150, 50, 1),dtype=np.float32)\n",
        "Y = np.ones((size, 6), dtype=np.float32)\n",
        "# input_length = np.ones((batch_len, 1), dtype=np.int64) * \\\n",
        "#                         (self.img_width // self.downsample_factor - 2)\n",
        "# label_length = np.zeros((batch_len, 1), dtype=np.int64)\n",
        "\n",
        "for j, idx in enumerate(curr_idx):\n",
        "  # 1. Get the image and transpose it\n",
        "  img = test_data[idx].T\n",
        "  # 2. Add extra dimenison\n",
        "  img = np.expand_dims(img, axis=-1)\n",
        "  # 3. Get the correpsonding label\n",
        "  text = test_labels[idx]\n",
        "  # 4. Include the pair only if the captcha is valid\n",
        "  if is_valid_captcha(text):\n",
        "    label = [char_to_labels[ch] for ch in text]\n",
        "    X[j] = img\n",
        "    Y[j] = label\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwZt9d789Y7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_eval(x,y,model):\n",
        "  preds=model.predict(x)\n",
        "  pred_texts=decode_batch_predictions(preds)\n",
        "  cnt=0\n",
        "  orig_texts = []\n",
        "  for label in y:\n",
        "      text = ''.join([labels_to_char[int(x)] for x in label])\n",
        "      orig_texts.append(text)\n",
        "  \n",
        "  for i in range(len(y)):\n",
        "    if pred_texts[i]==orig_texts[i]:\n",
        "      cnt=cnt+1\n",
        "  return cnt/len(pred_texts)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xywr5CIc9ZAF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "397d3f53-b5e4-4ad7-b812-9f086e6bcaa2"
      },
      "source": [
        "acc=my_eval(X,Y,prediction_model)\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1655\n",
            "0.8275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sES48Qv9ZCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.compat.v2.keras.models import model_from_json\n",
        "\n",
        "# json file 열기\n",
        "json_file = open(\"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/model/captcha_model_bk.json\", \"r\")\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "# # json파일로부터 model load\n",
        "# loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# # model에 weight 로드하기\n",
        "# weight = '/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/model/captcha_model_bk.h5'\n",
        "# loaded_model.load_weights(weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zEEHdXR9Yyj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "1195411d-6ae8-4013-8744-372bdfe6fdde"
      },
      "source": [
        "loaded_model = model_from_json(loaded_model_json)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-235-e9d7cd510e14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/model_config.py\u001b[0m in \u001b[0;36mmodel_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    371\u001b[0m             custom_objects=dict(\n\u001b[1;32m    372\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    374\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    985\u001b[0m     \"\"\"\n\u001b[1;32m    986\u001b[0m     input_tensors, output_tensors, created_layers = reconstruct_from_config(\n\u001b[0;32m--> 987\u001b[0;31m         config, custom_objects)\n\u001b[0m\u001b[1;32m    988\u001b[0m     model = cls(inputs=input_tensors, outputs=output_tensors,\n\u001b[1;32m    989\u001b[0m                 name=config.get('name'))\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mreconstruct_from_config\u001b[0;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[1;32m   2017\u001b[0m   \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2019\u001b[0;31m     \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2020\u001b[0m   \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2021\u001b[0m   \u001b[0;31m# Nodes that cannot yet be processed (if the inbound node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   1999\u001b[0m       \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdeserialize_layer\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2001\u001b[0;31m       \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialize_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2002\u001b[0m       \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0;32m--> 362\u001b[0;31m         config, module_objects, custom_objects, printable_module_name)\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    319\u001b[0m   \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_registered_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m   \u001b[0mcls_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown layer: CTCLayer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBmM5Hav9Yth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N6piHKg9Ylc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YWYB-WW9YjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riV5AuPn9YhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bca6fUPX9YfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui4NV6iRdDkM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f2f4922-15ed-4df0-94f8-2babc510489d"
      },
      "source": [
        "# 모델저장\n",
        "from keras.models import model_from_json\n",
        "model_json = model.to_json()\n",
        "with open(\"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/model/newcaptcha_model.json\", \"w\") as json_file:\n",
        "  json_file.write(model_json)\n",
        "\n",
        "# 가중치 저장\n",
        "model.save_weights(\"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/model/newcaptcha_weight.h5\")\n",
        "\n",
        "# Prediction 모델저장\n",
        "from keras.models import model_from_json\n",
        "prediction_model_json = prediction_model.to_json()\n",
        "with open(\"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/model/newcaptcha_prediction_model.json\", \"w\") as json_file:\n",
        "  json_file.write(prediction_model_json)\n",
        "\n",
        "# Prediction 가중치 저장\n",
        "prediction_model.save_weights(\"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/model/newcaptcha_prediction_weight.h5\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSiaJi5_7WD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.compat.v2.keras.models import model_from_json\n",
        "\n",
        "# 모델, weight 로드\n",
        "json_file = open(\"/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/model/newcaptcha_prediction_model.json\", \"r\")\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "# json파일로부터 model load\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# model에 weight 로드하기\n",
        "# weight = '/content/drive/My Drive/KPMG/CAPTCHA-BREAK=AI/model/newcaptcha_prediction_model.h5'\n",
        "# loaded_model.load_weights(weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFbslI7T74oA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model에 weight 로드하기\n",
        "weight = '/content/drive/My Drive/KPMG/CAPTCHA-BREAK-AI/model/newcaptcha_prediction_weight.h5'\n",
        "loaded_model.load_weights(weight)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
